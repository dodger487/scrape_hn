From day one, Iâ€™ve always been driven by the end result of the software I was coding and less so about the magic that was happening underneath. Seeing the ubiquitous â€œHello Worldâ€ appear in terminal was astonishing to me. The further you go, though, the more that magic becomes an art one must master either by necessity or from our inherent curiosity: Computer Science.

Todayâ€Šâ€”â€Šwe more or less dive into one such topic that suits the discipline well. If youâ€™ve ever wondered how Swiftâ€™s compiler does some neat optimizations (and other stuff!), today is your day. If not, wellâ€Šâ€”â€Šyouâ€™re already here ğŸ˜„!

The hot takes on whether or not recursive functions are a good idea or an unforgivable mistake are out there. No matter which camp you fall in, they naturally show how tail call elimination happens and why itâ€™s so awesome.

Think about some of the recursive functions youâ€™ve seen or authored. A lot of them involve the recursive invocation to occur at the end of said function:

Certainly not always the case, but when the last call the function makes is to itself, weâ€™ve got ourselves a tail recursive function. Recursive functions naturally lend themselves to this setup, and theyâ€™re logically easier to reason about to boot.

That means they can be easily maintained later on. But, actually, if youâ€™re needing to refactor a recursive function at your 9â€“5, maybe just move on to the next Github Issue ğŸ˜œ.

Recursive or not, typically when functions are called they do a few things to establish their own call frame. A call frame tells us about the functionâ€™s details; import stuff like its local variables, parameters and return address.

Itâ€™s a functionâ€™s version of a Facebook account, full of juicy details. And with those juicy details, the compiler can look at all of them holistically and make smarter choices than we would.

If youâ€™re a fan of the always helpful Time Profilerâ€Šâ€”â€Šyouâ€™ve seen this in action. It uses a service deep inside the kernel that samples what the CPUs are up to, all at a blistering 1000x per second ğŸ˜±!

As Chad Woolf explained in an excellent WWDC session over the topic, if we sampled our function above at the point of the tail call weâ€™d see the base of its call frame and know who called into itâ€Šâ€”â€Šitself. And, you can keep going down the chain, checking into the frame pointers on the stack until you hit rock bottom. In fact, thatâ€™s how backtraces are born.

If we invoked our sample code above, it might look something like this right before the tail call on the call stack:

Now, we can envision our recursive function if it ran all the way through:

â€¦and on and on that call stack would grow, if the recursive function was called, say, 1,000 times. Luckily for us, itâ€™s likely to only happen onceâ€Šâ€”â€Šbut thatâ€™s because itâ€™s fake code and my fake code performs great ğŸ˜‰.

That type of scenario can be taxing and inefficient. If, say, our code sample freaked out a bit with its synchronousLogin() invocation and re-entered our function hundreds of times:

Thatâ€™s when the compiler can save our tail by optimizing this kind of code by memory reuse, keeping caches hot and saving precious stack memory via a process calledâ€¦.. tail call elimination! It can even bring performance up to par with an iterative variant of the same code.

The best part is, how it works isnâ€™t magical: It just prevents the compiler from pushing more frames, thus preventing more stack growth. Why not let the callee reuse the frame stack of the caller instead of popping another one on?

Hereâ€™s something I never thought Iâ€™d say: Recursion explained a computer sceincey thing easier to me than other non-recursive examples.

That said, tail call elimination is not mutually exclusive to recursionâ€Šâ€”â€Šthough itâ€™s a case study for its benefits. In fact, in Appleâ€™s sample code in their WWDC session mentioned above, drawRect: reaps its rewards even though itâ€™s not an inherently recursive function.

Apple provided an â€œAhâ€Šâ€”â€ŠI get it now!â€ non-recursive example that went something like this:

Without tail call optimizations, this process would look something like this at the end of the function:

We can see that the call to drawPath() is the last thing thatâ€™ll happen inside drawRect. So we can reason that, heyâ€Šâ€”â€ŠdrawPathâ€Šâ€”â€Šdoesnâ€™t need anything from drawRectâ€™s stack frame. Further, why return to drawPath at all when itâ€™s just going to return right back to its caller?

Tail call elimination shuffles things around to address those concerns:

So yeahâ€Šâ€”â€Šrecursion doesnâ€™t get all the fun here. In particular, in our world as iOS developers it can also happen if:

There are some use cases to disabling the magic here if youâ€™d so choose. Namely, for the sake of profilingâ€Šâ€”â€Šyouâ€™ll get a true, clean stack trace by turning this off.

Time Profiler will report the call stack as it appears with tail call elimination at work. Though, thatâ€™s not the actual call sequence that happenedâ€Šâ€”â€Šcall tail optimization made it that way. If you want to really see how things went down, head over to your appâ€™s project settings in Xcode and set the following compiler flag:

And then enjoy your bonafide results in time profiler.

I went several years without knowing anything at all about tail call elimination. And guess whatâ€Šâ€”â€Šit was all good. This information wonâ€™t change your appâ€™s code base into a pristine case study, rather, itâ€™s just fun to learn about, ya know?

It makes me think of how our discipline is one of several carefully crafted abstractions, one on top of the other. And slowly, we keep peeling apart the layers and learning more and more about how our iOS software actually ticks.

Until next timeâ€Šâ€”â€Šthanks for reading âœŒï¸.|||

From day one, Iâ€™ve always been driven by the end result of the software I was coding and less so about the magic that was happening underneath. Seeing the ubiquitous â€œHello Worldâ€ appear in terminalâ€¦