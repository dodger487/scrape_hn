Facebook has admitted that it observed attempts to spread propaganda on its site, apparently orchestrated by governments or organised parties.

The firm has seen "false news, disinformation, or networks of fake accounts aimed at manipulating public opinion", it revealed in a new report.

"Several" such cases during the US presidential election last year required action, it added.

Some of the activity has been of a "wide-scale coordinated" nature.

Fake accounts were created to spread information stolen from email accounts during the 2016 US presidential election, the firm noted, though it said the volume of such activity was "statistically very small".

Facebook did not attribute it to any specific state or actor, but it did say that its data did not contradict the US Director of National Intelligence's claim that Russia was involved.

The company added that efforts to tackle "information operations" had led to the removal of more than 30,000 fake accounts in France - where a presidential election is currently under way.

In general, Facebook said it faced a new challenge in tackling "subtle and insidious forms of misuse, including attempts to manipulate civic discourse and deceive people".

Facebook described much of the activity as "false amplification" - which included the mass creation of fake accounts; the coordinated sharing of content and engagement with that content (such as likes); and the distribution of "inflammatory and sometimes racist memes".

It added, however, that there was not much evidence that automated bots had been set up to do this, but humans appeared to be directly involved.

"We have observed many actions by fake account operators that could only be performed by people with language skills and a basic knowledge of the political situation in the target countries, suggesting a higher level of coordination and forethought," the report explained.

The apparent objectives of those behind the propaganda efforts included one or more of the following:

Facebook said that it was working on a variety of methods to curb the spread of propaganda on its platform.

These included building new products to help stamp out fake news and creating new systems - some with artificial intelligence capabilities - to help quicken the response to reports of fake accounts or spam.

The rise in people who get their news from social media meant that propaganda on sites like Facebook was an important issue, suggested Ewan Lawson, an information operations expert at the Royal United Services Institute.

"If you can influence what people are reading and what version of the truth they're being shown, it has the potential to have an effect," he told the BBC.

However, he added, it was difficult to quantify this.

"I think the most interesting thing is the fact that Facebook has come out so publicly - there's been a sense of a little bit of reluctance on the part of the large communications companies to acknowledge the extent to which they have been abused," he said.

Mr Lawson also said he thought Facebook's efforts to tackle the problem were "very positive".|||

The social network says it has seen highly organised attempts to manipulate information on the site.