â€œAre doctors going to be replaced by computers soon?â€

We also sawÂ one possible answer: â€œYesâ€, which we are going to investigate in this series of articles. Over the next few posts we willÂ start building a foundation for answering this question, by defining and exploring some of the basic concepts.

I want to start byÂ talking about medicine as it relates to automation. To understand if automation is possible, we need to understand the medical process. In particular, we need to know what is going on in the heads of doctors, since that is what we want to replicate or improve upon.

First up, we are mainly talking about diagnostic medicine. Autonomous robots exist, but they arenâ€™t ready to perform surgery. Iâ€™mÂ personally super excited by the advances in robotics in recent years, but evenÂ folding clothes and opening doorsÂ at a five year old level is a fair way offÂ ğŸ™‚

Diagnostic medicine is the mostly non-physical part of being a doctor. DiagnosisÂ and treatment choices, with a few other elements. When most people think â€œdiagnostic medicineâ€, they probably think of Gregory House, MD. The super-smart Sherlock Holmes character who thinks really hard about a problem to solve it. These people are usually characterised by having vast knowledge, amazing intuition and poor social skills.

This isnâ€™t medicine. Or more accurately, it is a tiny part of medicine.

The vast majority of medicalÂ practice isnâ€™t knowledge-based at all.

Story time! Decades ago everyone thought being a medical expert was about knowledge, and computer scientists tried to automate the knowledge base of medicine. The earliest computer system that outperformed doctors was MYCIN, an AI system that was developed in Stanford in the mid 1970s. It was knowledge based, codifying the process of identifying the likely cause of infection and choosing a treatment for it in a set of 600 rules. For to doctors reading this, these rules are the same as aÂ flowchart based treatment guideline. For example, a guideline for pneumonia assessment:

To turn this into a computer program, like MYCIN, the flowchart is converted intoÂ bunch of nested if/then statements, like:

There was more to MYCIN, but that was the core of how it worked. With the benefit of 40 years of post-MYCIN experience, we can say a couple of things about it:

The standard explanation for this failure to make a clinical impact was that MYCIN required time-consuming manual data input and that the IT infrastructure didnâ€™t exist in the 70s to make use of it. But this argument isnâ€™t very satisfying, because those challenges have long been solved. We can automatically mine electronic health records for phrases or keywords to populate our systems, and we certainly arenâ€™t bottlenecked by computation or electronic infrastructure anymore. But we still donâ€™t use MYCIN, or almost any of its successors.

To understand my take on the clinical failure ofÂ MYCIN, imagine going to the doctor for a cough. Your doctor asks you some questions, listens to your chest, takes your temperature and your pulse rate. They send off a sputum sample or blood test. They might even get a chest x-ray. And after all that, how long does it take them to decide on an antibiotic?

Seconds, probably. Most doctors would barely register the decision as a conscious choice.

The fact is, the knowledge and decision making part of medicine becomes automatic for doctors. There is a long history of cognitive science research inÂ medicine (I personally thinkÂ this seminal paperÂ is required reading for anyone that wants to understand medical expertise) and it shows that senior doctors donâ€™t really think about many of their decisions. They engage in an experience based form of pattern matching. In fact, senior doctors often perform worse if you slow them down and force them to think.

This phenomenon certainly isnâ€™t limited to doctors, as the literature on expertise reveals moreÂ generally. Improved rapid pattern matching is thought to account for the performance differences between chess grandmasters and lesser experts (read page 10 and 11 of this book), as well as expertise in numerous other domains (music, sport, writing and so on). As stated in a more recent review paper

For the doctors whoÂ are a bit put off by that characterisation of medicine, let me frame it another way;Â Medicine is as much an art as a science. Weâ€™ve all heard that before, and it sounds good, right? In fact, it is often used as a defense against predictions of automation (like in the top comment of this reddit thread, or in the many articles by doctors arguing that automation is unlikely). I agree with the statement, but I think it has been significantly misinterpreted.

When we say â€œmedicine is an artâ€, we mean that some parts of the process are ill-defined and canâ€™t be written down or codified. That is what â€œa scienceâ€ is; a set of reliable well-defined rules. In medicine our gut is often just as useful as our knowledge. We see a patient and we justÂ know what is wrong with them. We get a sudden burst of inspiration and diagnose a rare disorderÂ we hadnâ€™t considered. We get the feeling our patient is about to crashÂ for no identifiable reason.

That is what subconscious pattern matching feels like from the inside. Your brain compares your patient against your experience, and returnsÂ a â€œbest matchâ€ answer. Without your conscious thought, and without needing you to invest much time.

The key point here is that the part of the medical process that MYCIN automated had a negligible cost (measured in time spent).Â Saving time on a process that takes between seconds and minutesÂ just isnâ€™t worth the effort of overhauling our current systems.

But all of this does raise an interesting question: what are diagnosticÂ doctors spending all their time on, if not â€œthinkingâ€?

They are looking, listening, touching, and measuring. These are mostly sensory tasks (with less complicated motor control elements), and they take up a big portion of a doctorâ€™s time. In fact, the largestÂ disruption in modern healthcareÂ history was due to the automation of perceptual (and minor motor control) processes â€“ clinical chemistryÂ services. Things like measuring electrolytes in serum. Between 1965 and now, one lab found that their workforce had decreased by about 25%, even as the volume of work significantly increased. This has resulted in an 80% reductionÂ in the per-test costÂ for clinical chemistry, which is exactly the sort of outcome we are hoping for in medicine.

Biologically it seems obvious that perception is an important task. Almost half our â€œupperâ€ brain is dedicated to sensory processing and integration.Â Everything elseÂ including planning, reasoning, moving, decision making, personality, morality, memory, all the other higher functions that distinguish humans from animals â€“ isÂ smooshed into the other half. Obviously, perception is a taskÂ worth spending our precious energy on.

The major stumbling block for automating perceptual tasks, and the difference between clinical chemistry and medicine more broadly, is that most perceptual tasks are not amenable to simple physical solutions. Rather than just measuring voltage differences with ion-selective electrodes or counting the number of shadowsÂ that pass a laser beam (biochemistry and cell counting respectively), doctors need toÂ see their patients.

For decades, machines were no good at this sort of â€œhuman-likeâ€ perception. Five year olds beat them by miles. So computer scientists solved other, more tractable problems. MYCIN asked a doctor to do all the perception and then automated the decision making. It was a problem that was solvable, but it wasnâ€™t a problem that was valuable.

The revolution that is happening in artificial intelligence can be understood in one idea;Â deep learning is really good at human-like perception. In fact, deep learning systems now perform around human level in a wide range of perceptual tasks, like visual object recognition and voice transcription. And because perception has such a big role in expertiseÂ we are achievingÂ superhuman performance in â€œexpert tasksâ€,Â like driving cars or playing complex games like Go. It turns out that these tasks were all bottle-necked by perception, notÂ decision making.

Machine learning guruÂ Andrew Ng has a rule of thumb â€“ â€œIf a typical human can do it in 1 second, so can deep learningâ€. My experience in medical applications suggests a slight restatement of this rule:

They key difference is that I have not noticed a distinctionÂ between the learnability of tasks that the â€œtypical personâ€Â can do quickly, and tasks that medical experts perform via subconscious pattern matching (although I will explore this nuance in more depth another day).

To return to the idea that â€œmedicine is an artâ€; if the art of medicine is integrating patient patterns and learning to make best use of that stored experience, thenÂ deep learning is automating the art rather than the science. Rather than a defense against automation, the art argument shows us why these techniques are more promising than previous approaches.

We can drive this home with an example. Take reading a chestÂ CAT-scanÂ in radiology, we can make a flowchart like this:

This is an actual diagnostic flowchart from this paperÂ published in a high quality journal. You can see how it can be turned into a computer program quite easily, but the most important thing is that every blue box is a perceptual task.Â Â Each term used (like â€œtree-in-budâ€œ, â€œbronchiectasisâ€ and so on) are patterns you see in the images.

You should recognise right away thatÂ there are no other tasks to solve. IfÂ you can perceive the patterns, you have the answer.

ThisÂ is why Prof Hinton was talking about radiology in his medpocalyptic predictions. The two medical specialties generally considered most â€œat riskâ€ are diagnostic radiology (my job!) and pathology, and both are almost entirely perceptual (finding patterns inÂ medical scans and microscope slides respectively).

The next obvious question is: how big are the â€œat-riskâ€ specialities? How much of medical expenditure is perceptual in nature, and therefore potentially solvable by deep learning?

Diagnostic Imaging (DI) and Pathology make up over a quarter of our total health budget (which in Australia is around 10% of GDP). In DI, about half of that cost is wages. So even if we just limit ourselves to those two specialties, that isÂ something like 1% of national GDP in wages. Quite staggering.

Other fields commonly thought of as â€œat-riskâ€ include dermatology and ophthalmology (for the â€œlooking at the skinâ€ and â€œlooking in the eyesâ€ components), but these are much smaller slices of the pie.

It is worth noting, however, that many other medical specialties have large perceptual components. Your local family doctor still spends a lot of time looking, listening and feeling. A surgical specialist does too, and relies a lot on radiology and pathology tests. A psychiatrist learns a lot from sight and sound.

So we might be looking at a technology that can doÂ parts of the work of most typesÂ of doctors, even if it canâ€™t replace all of the jobs. And that leads us to the topic of the next blog post â€“ understanding what we actually mean by â€œautomationâ€.

See you next week ğŸ™‚|||

Last post I introduced the big question - "Are doctors going to be replaced by computers soon?" We also sawÂ one possible answer: "Yes", which we are going to investigate in this series of articles. Over the next few posts we willÂ start building a foundation for answering this question, by defining and exploring some of theâ€¦