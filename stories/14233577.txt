Aumann's agreement theorem says that two people acting rationally (in a certain precise sense) and with common knowledge of each other's beliefs cannot agree to disagree. More specifically, if two people are genuine Bayesian rationalists with common priors, and if they each have common knowledge of their individual posterior probabilities, then their posteriors must be equal.[1] This theorem holds even if the people's individual posteriors are based on different observed information about the world. Simply knowing that another agent observed some information and came to their respective conclusion will force each to revise their beliefs, resulting eventually in total agreement on the correct posterior. Thus, two rational Bayesian agents with the same priors and who know each other's posteriors will have to agree.

A question arises whether such an agreement can be reached in a reasonable time and, from a mathematical perspective, whether this can be done efficiently. Scott Aaronson has shown that this is indeed the case.[2] Of course, the assumption of common priors is a rather strong one and may not hold in practice. However, Robin Hanson has presented an argument that Bayesians who agree about the processes that gave rise to their priors (e.g., genetic and environmental influences) should, if they adhere to a certain pre-rationality condition, have common priors.[3]

Studying the same issue from a different perspective, a research paper by Ziv Hellman considers what happens if priors are not common. The paper presents a way to measure how distant priors are from being common. If this distance is ε then, under common knowledge, disagreement on events is always bounded from above by ε. When ε goes to zero, Aumann's original agreement theorem is recapitulated.[4] In a 2013 paper, Joseph Halpern and Willemien Kets argued that "players can agree to disagree in the presence of ambiguity, even if there is a common prior, but that allowing for ambiguity is more restrictive than assuming heterogeneous priors."[5]|||

