Last year, Alphabet’s DeepMind division captured the world’s attention by besting humanity’s top player in the game of Go. The achievement, which many experts predicted was still a decade off, showed the rapid progress being made in the world of artificial intelligence. DeepMind subsequently announced that its next goal in gaming was mastering StarCraft, a classic PC game that is a staple of competitive e-sports. Facebook also threw its hat in the ring, creating an open-source framework so that developers could work on solving StarCraft using the social network’s AI toolkit.

Now a team from China’s Alibaba has published a paper describing a system that learned to execute a number of strategies employed by high-level players without being given any specific instruction on how best to manage combat. Like many deep learning systems, the software improved through trial and error, demonstrating the ability to adapt to changes in the number and type of troops engaged in battle.

“BiCNet can handle different types of combats under diverse terrains with arbitrary numbers of AI agents for both sides. Our analysis demonstrates that without any supervisions such as human demonstrations or labelled data, BiCNet could learn various types of coordination strategies that is similar to these of experienced game players,” the authors wrote in a paper published to arXiv. “Moreover, BiCNet is easily adaptable to the tasks with heterogeneous agents. In our experiments, we evaluate our approach against multiple baselines under different scenarios; it shows state-of-the-art performance, and possesses potential values for large-scale real-world applications.”

This type of AI may one day compete in tournaments hosted by Alibaba itself. But like AI trained to play poker, the developers hope that this system, or least this type of system, will have a broad range of real-world applications beyond just beating humans at StarCraft. “Real-world artificial intelligence (AI) applications often require multiple agents to work in a collaborative effort. Efficient learning for intra-agent communication and coordination is an indispensable step towards general AI.” It will be extra ironic if a sentient, SkyNet type of artificial intelligence is one day created from a software program trained on virtual space marines.|||

Last year, Alphabet’s DeepMind division captured the world’s attention by besting humanity’s top player in the game of Go. The achievement, which many experts predicted was still a decade off,...