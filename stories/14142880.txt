I love podcasts. But you canâ€™t use Google to search for something that was said during a podcast. And if you canâ€™t listenâ€”because of physical disability, personal preference, learning style, or any other reasonâ€”youâ€™ll never know whatâ€™s being said. An entire vibrant, conversational, fun corner of the digital media world is closed to you.

The solution is clear: Create a text transcript for every podcast! Iâ€™m pretty sure that this will eventually happen, but weâ€™re not there yet. Speech-to-text technology just isnâ€™t good enough, and human-created transcripts are more expensive than most podcasts can afford.

There are services that offer human transcriptions of podcastsâ€”Iâ€™ve used both CastingWords and Rev, but they arenâ€™t cheap. The cheapest Iâ€™ve seen is $1 per minute. Thatâ€™s not unreasonable if youâ€™re a highly capitalized commercial podcast with a big budget, but Iâ€™d wager that 98 percent of podcasts would lose money if they had to pay $1 per minute for transcripts.

But beyond that, these human-based transcription services still generate transcripts that are full of errors, misunderstandings, and nonsensical statements. The more arcane or technical the discussionâ€”or the more voices on a podcastâ€”the worse it can get. If you really want your transcript to be good, you have to go over it yourself, preferably by listening alongâ€”and that takes time. The cost just went up even more.

The great hope lies in software transcriptions, which can either ease the burden of human transcriptionists or replace them entirely. There are a few platforms currently offering speech-to-text transcriptionsâ€”I used Googleâ€™s API via the Auphonic serviceâ€”and they cost a lot less than paying a human to transcribe them. But as you might expect, the results are comical at best , unintelligible at worst.

I ran last weekâ€™s Six Colors Secret Subscriber Podcast through the Google engine, just as a sample. Hereâ€™s something Dan said, which I transcribed and edited:

Right, and I think the hugest win here is this idea that Workflow succeeded in an environment where Apple did very little to foster anything in that area. From the scripting side and the Automator side, I think they were always kind of awkward because you could be very good at automating or scripting, but it always felt to me like a weird middle ground where people who are not technicalâ€¦ there was just no chance that they were going to sit down to write an AppleScript. And then for a lot of people who are very technicalâ€”we know many programmers and Iâ€™m one of these people who did work in programmingâ€”I have the hardest time grokking an AppleScript.

And hereâ€™s what the machine presented to me:

Right and I think thatâ€™s an amazing and the sort of like you just win here is this idea that you know workflow succeed in an environment where Apple did very little to sort of foster anything in that area from the scripting side in like the automator side I think they were always kind of awkward because, you could be very good at automated or automating or scripting put it always to me felt like a weird Middle Ground where people who are not technical like there was just no chance like, weâ€™re going to sit down to write an apple script and then for a lot of people who are very we know many programmers who and I will Iâ€™m one of these people who did work in programming I have the hardest time cracking an apple script

And that was one of the cleaner passages. I cleaned it up by going over the audio and correcting all of the mistakes (and making some editorial judgment to remove some filler words and false starts).

This also points out another problem with text transcripts of talking, namely that we donâ€™t talk the way we write. Even the most conversational of writers ğŸ‘‹ğŸ» will be more direct than a transcript of how people speak. The way our brains process speech is very different from the way they process writing. If I were to â€œtranslateâ€ Danâ€™s statement into writing, it might look like this:

Hereâ€™s the good news: While these machine translations arenâ€™t readable, they are getting good enough to fuel search engines. A great proof of concept is this one from David Smith, which covers seven different podcasts.

Iâ€™m a little baffled why Google hasnâ€™t just indexed the contents of every podcast on the Internet and poured it into the Google search engine. Davidâ€™s engine works well because the computerized transcript is attached to a time code for that podcast episode, so when you find a search result you can click to hear what was really said, rather than relying on a baffling transcript.

This could go a long way to addressing the searchability of podcasts, which is why Iâ€™m hoping to (slowly) add automatic transcripts to all my podcasts. They wonâ€™t be great readingâ€”which is why in the long term this technology needs to get much better in order to support people who are unable to listen at allâ€”but they will help feed search engines and make it easier to find that moment when I first had Matt Fractionâ€™s â€œHawkeyeâ€ recommended to me.

[If you appreciate articles like this one, help us continue doing Six Colors (and get some fun benefits) by becoming a Six Colors subscriber.]|||

Six Colors by Jason Snell and Dan Moren