Now that weâ€™ve got the pieces working, itâ€™s time to build our masterpiece.

We do want to check and make sure that consumption of PubNubâ€™s Twitter stream is working, so letâ€™s get to it!

Twitter does have their own API, but PubNub has made consuming it easy by providing us with a public subscription key. As I noted in Part 2, PubNubâ€™s Twitter stream only pulls in 50 messages a second, but weâ€™re throttling the number of messages sent to IBM Watsonâ€™s sentiment analysis to just 1,000/day anyways.

If youâ€™re interested in sifting through all of the tweets every second because you have a less popular keyword, or if youâ€™re paying for IBMâ€™s services, checkout the last section: BONUSâ€Šâ€”â€ŠPart 7: The Ultimate Stream

I initially wrote this project in Python because thatâ€™s the language Iâ€™m most familiar in, but Iâ€™ve gone ahead and added Node JS versions of all the scripts too! These could easily be adapted into another language thanks to PubNubâ€™s many SDKs.

To use PubNub on your own machine (or perhaps a Raspberry Pi?), you need to install it using the command line:

You can see other installation methods here.

To see if the Twitter feed will work, just run the twitterTest.py script! You can copy it to your computer by saving it to a folder you usually run code from or by creating a file with and pasting it.

Give it a second or two to actually find a tweet that matches our criteria on line 32 ([â€˜Trumpâ€™,â€™trumpâ€™,â€™POTUSâ€™,â€™potusâ€™]), and you should start seeing messages print out:

If that works, we can move on to the master script!

To use PubNub on your own machine, you need to install it using the command line:

You can see other installation methods here.

To see if the Twitter feed will work, just run the twitterTest.js script! You can copy it to your computer by saving it to a folder you usually run code from or by creating a file with and pasting it.

Give it a second or two to actually find a tweet that matches our criteria on line 16 (Trump, trump, or any capitalization of POTUS), and you should start seeing messages print out:

If that works, we can move on to the master script!

The most important thing you need to do before you try to run this script is add your PubNub keys:

Lines 1â€“5 import all of our modules.

Lines 7â€“20 are where we configure PubNub with both the public Twitter key and the private keys associated with our account.

Lines 23â€“33 handle the results of any publish call and will tell us if a publish was successful.

Lines 36â€“71 handle the subscription to the Twitter stream. If you want to change what keywords are looked for, you can do so on line 40 (â€˜Donaldâ€™ was omitted because I kept picking up tweets about McDonaldâ€™s). Starting at line 64, we actually handle the tweetsâ€Šâ€”â€Šfirst searching for any of the keywords and then publishing the message to our sentiment-analysis channel (which is associated with the IBM Watson block).

Lines 74â€“134 handle the subscription to the sentiment analysis output. On line 78 we specify our Initial State bucket key (â€œpubnubtrumpâ€). We will need this to create our bucket in Initial State! Lines 99â€“134 handle the sentiment analysis response. We build the payload to send to our Initial State block here (using the merge function on lines 137â€“145) and then publish it.

Lines 149â€“155 are where we configure our PubNub channel subscriptions and tell them which callback class to use.

You should see the payload start printing out and output in your PubNub block debug console!

The most important thing you need to do before you try to run this script is add your PubNub keys:

Lines 3â€“12 are where we configure PubNub with both the public Twitter key and the private keys associated with our account.

Lines 17â€“40 handle the subscription to the Twitter stream. If you want to change what keywords are looked for, you can do so on line 25 (â€˜Donaldâ€™ was omitted because I kept picking up tweets about McDonaldâ€™s). Starting at line 25, we actually handle the tweetsâ€Šâ€”â€Šfirst searching for any of the keywords and then publishing the message to our sentiment-analysis channel (which is associated with the IBM Watson block).

Lines 42â€“88 handle the subscription to the sentiment analysis output. On line 48 we specify our Initial State bucket key (â€œpubnubtrumpâ€). We will need this to create our bucket in Initial State! Lines 51â€“85 handle the sentiment analysis response. We build the payload to send to our Initial State block here and then publish it.

Lines 91â€“99 are where we configure our PubNub channel subscriptions.

You should see the payload start printing out and output in your PubNub block debug console!

Time to check the tweets out in a dashboard.

Time to look at our dashboard! We need to create a bucket with the bucket key from our script like we did in Part 3.

So click the +cloud icon at the top of your bucket shelf to create a new streaming bucket. Name your bucket and check the â€œConfigure Endpoint Keysâ€ box to specify the bucket key.

This must match the key you just sent through PubNub so enter â€œpubnubtrumpâ€. I named my bucket â€œTrump Twitter ğŸ¦â€.

Click the â€œCreateâ€ button at the bottom and the new bucket should be listed at the top of your shelf.

Click on that bucket and you should see Tiles pop up for Tweet, Positive Level, Neutral Level, Negative Level, and Score.

If you want to make your dashboard both more informative and attractive, keep reading!

You can find support articles on what you can do in Tiles, but Iâ€™m going to walk through the main things I changed with links to the relevant support article:

And now you have a beautiful dashboard that updates in realtime! Itâ€™s also interactiveâ€Šâ€”â€Šmouse over the different tiles to see signal names and values:|||

How to build a live dashboard that analyzes and publishes the sentiment of Tweets related to a keyword in realtime with IBM Watson, Bluemix, PubNub, and Initial State.