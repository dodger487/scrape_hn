This has to do with how the type works in Swift, and how the method works. The 'ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ ' is what's known as an emoji sequence, which is rendered as one visible character in a string. The sequence is made up of objects, and at the same time it is made up of objects. If you check the character count of the string, you'll see that it is made up of four characters, while if you check the unicode scalar count, it will show you a different result: Now, if you parse through the characters and print them, you'll see what seems like normal characters, but in fact the three first characters contain both an emoji as well as a zero-width joiner in their : for char in "ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦".characters { print(char) let scalars = String(char).unicodeScalars.map({ String($0.value, radix: 16) }) print(scalars) } // ğŸ‘©â€ // ["1f469", "200d"] // ğŸ‘©â€ // ["1f469", "200d"] // ğŸ‘§â€ // ["1f467", "200d"] // ğŸ‘¦ // ["1f466"] As you can see, only the last character does not contain a zero-width joiner, so when using the method, it works as you'd expect. Since you aren't comparing against emoji containing zero-width joiners, the method won't find a match for any but the last character. To expand on this, if you create a which is composed of an emoji character ending with a zero-width joiner, and pass it to the method, it will also evaluate to . This has to do with being the exact same as , which tries to find an exact match to the given argument. Since characters ending with a zero-width joiner form an incomplete sequence, the method tries to find a match for the argument while combining characters ending with a zero-width joiners into a complete sequence. This means that the method won't ever find a match if: the argument ends with a zero-width joiner, and the string to parse doesn't contain an incomplete sequence (i.e. ending with a zero-width joiner and not followed by a compatible character). However, since the comparison only looks ahead, you can find several other complete sequences within the string by working backwards: s.range(of: "\u{1f466}") != nil // true s.range(of: "\u{1f467}\u{200d}\u{1f466}") != nil // true s.range(of: "\u{1f469}\u{200d}\u{1f467}\u{200d}\u{1f466}") != nil // true // Same as the above: s.contains("\u{1f469}\u{200d}\u{1f467}\u{200d}\u{1f466}") // true The easiest solution would be to provide a specific compare option to the method. The option performs the comparison on an exact character-by-character equivalence. As a side note, what's meant by character here is not the Swift , but the UTF-16 representation of both the instance and comparison string â€“ however, since doesn't allow malformed UTF-16, this is essentially equivalent to comparing the Unicode scalar representation. Here I've overloaded the method, so if you need the original one, rename this one or something: Now the method works as it "should" with each character, even with incomplete sequences:|||

